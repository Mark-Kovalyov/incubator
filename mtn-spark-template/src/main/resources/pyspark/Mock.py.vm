import pyspark
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType,StructField, StringType, IntegerType, LongType, DoubleType

schema = StructType([
  StructField("empno",      LongType()),
  StructField("ename",      StringType()),
  StructField("job",        StringType()),
  StructField("mgr",        LongType()),
  StructField("hiredate",   StringType()),
  StructField("sal",        DoubleType()),
  StructField("comm",       DoubleType()),
  StructField("deptno",     LongType())
])

data = [
  (7369,"SMITH","CLERK", 7902, "1980-12-17", 800.0, None, 20),
  (7499,"ALLEN","SALESMAN", 7698, "1981-02-20", 1600.0, 300.0, 30),
  (7521,"WARD","SALESMAN", 7698, "1981-02-22", 1250.0, 500.0, 30),
  (7566,"JONES","MANAGER", 7839, "1981-04-02", 2975.0, None, 20),
  (7654,"MARTIN","SALESMAN", 7698, "1981-09-28", 1250.0, 1400.0, 30),
  (7698,"BLAKE","MANAGER", 7839, "1981-05-01", 2850.0, None, 30),
  (7782,"CLARK","MANAGER", 7839, "1981-06-09", 2450.0, None, 10),
  (7788,"SCOTT","ANALYST", 7566, "1987-04-19", 3000.0, None, 20),
  (7839,"KING","PRESIDENT", None, "1981-11-17", 5000.0, None, 10),
  (7844,"TURNER","SALESMAN", 7698, "1981-09-08", 1500.0, 0.0, 30),
  (7876,"ADAMS","CLERK", 7788, "1987-05-23", 1100.0, None, 20),
  (7900,"JAMES","CLERK", 7698, "1981-12-03", 950.0, None, 30),
  (7902,"FORD","ANALYST", 7566, "1981-12-03", 3000.0, None, 20),
  (7934,"MILLER","CLERK", 7782, "1982-01-23", 1300.0, None, 10)
]

empdf = spark.createDataFrame(data, schema)

empdf.printSchema()